{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "id": "KYabw3KmN4ih",
        "outputId": "36eec17d-57e3-48c7-f370-dcd2fee2661b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!pip install --upgrade azure-cognitiveservices-vision-computervision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting azure-cognitiveservices-vision-computervision\n",
            "  Downloading azure_cognitiveservices_vision_computervision-0.9.0-py2.py3-none-any.whl (39 kB)\n",
            "Collecting azure-common~=1.1\n",
            "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
            "Collecting msrest>=0.5.0\n",
            "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 2.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2021.10.8)\n",
            "Collecting isodate>=0.6.0\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 484 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.3.1)\n",
            "Requirement already satisfied: requests~=2.16 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from isodate>=0.6.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (3.2.0)\n",
            "Installing collected packages: isodate, msrest, azure-common, azure-cognitiveservices-vision-computervision\n",
            "Successfully installed azure-cognitiveservices-vision-computervision-0.9.0 azure-common-1.1.28 isodate-0.6.1 msrest-0.6.21\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "8X0VeMOcN4ir"
      },
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "\n",
        "from array import array\n",
        "import os\n",
        "from PIL import Image\n",
        "import sys\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Iej4TXN4N4it"
      },
      "cell_type": "code",
      "source": [
        "subscription_key = '7141aa2c2008435fb3c7cd3d0988e595'\n",
        "endpoint = 'https://ritikacs.cognitiveservices.azure.com/'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ALvWJIJCN4iu"
      },
      "cell_type": "code",
      "source": [
        "client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "49nRUVzFN4iw"
      },
      "cell_type": "code",
      "source": [
        "baseURL = 'https://ritikastorageacc.blob.core.windows.net/myimages/'\n",
        "# https://tomyumtum.blob.core.windows.net/img/1.jpg\n",
        "images = ['1.jpg','2.jpg','3.jpg','4.jpg']\n",
        "names = ['be grateful quote','journey quote','people','dog & cycle']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "o8tWHn5aRxcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = client.describe_image(baseURL + '1.jpg')\n",
        "print(result)"
      ],
      "metadata": {
        "id": "WY_ub99-RLr-",
        "outputId": "32b56763-23a7-4944-c760-210ff177aa45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'additional_properties': {}, 'tags': ['text', 'letter'], 'captions': [<azure.cognitiveservices.vision.computervision.models._models_py3.ImageCaption object at 0x7fd1786d2dd0>], 'request_id': '6d18e6a8-ea86-4698-ab73-51ccb6b59101', 'metadata': <azure.cognitiveservices.vision.computervision.models._models_py3.ImageMetadata object at 0x7fd1786d2f10>, 'model_version': '2021-05-01'}\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "LxW2d-DtN4iy"
      },
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for image in images:\n",
        "    result = client.describe_image(baseURL + image)\n",
        "    results.append(result)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "iECJBuBTN4iz",
        "outputId": "f157b1bb-6575-4287-db73-4c58a37b7a6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "print('image descriptions:')\n",
        "i = 0\n",
        "for result in results:\n",
        "    if(len(result.captions)==0):\n",
        "        print('No descriptions present')\n",
        "    else:\n",
        "        for caption in result.captions:\n",
        "            print('Image title: ' + names[i])\n",
        "            print(str(caption.text))\n",
        "            print(str(caption.confidence))\n",
        "            i = i+1\n",
        "            print()\n",
        "        "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image descriptions:\n",
            "Image title: be grateful quote\n",
            "text, letter\n",
            "0.9251276254653931\n",
            "\n",
            "Image title: journey quote\n",
            "a snowy mountain range\n",
            "0.4018929898738861\n",
            "\n",
            "Image title: people\n",
            "a group of people riding bikes\n",
            "0.45363667607307434\n",
            "\n",
            "Image title: dog & cycle\n",
            "a dog sitting on a bench\n",
            "0.367296427488327\n",
            "\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "rOdGMpz_N4i1",
        "outputId": "93df7d20-498a-46e1-d781-7d86940288b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# Categories (Image analysis)\n",
        "# exception handling to ignore any error-> this is production\n",
        "# in production-> you log the error into a error.txt file \n",
        "# demo only-> ignore the error \n",
        "\n",
        "analysis = []\n",
        "for image in images:\n",
        "    analyze = client.analyze_image(baseURL +image, ['categories'])\n",
        "    analysis.append(analyze)\n",
        "\n",
        "print('image captions:')\n",
        "\n",
        "for i,result in enumerate(analysis):\n",
        "    try:\n",
        "        if(len(result.categories)==0):\n",
        "            print('No descriptions present')\n",
        "        else:\n",
        "            for category in result.categories:\n",
        "                print('Image title: ' + names[i])\n",
        "                print(str(category.name))\n",
        "                print(str(category.score))\n",
        "                i = i+1\n",
        "                print()\n",
        "    except Exception as exp:\n",
        "        print(str(exp)) # in production, LOG error instead\n",
        "        pass\n",
        "        \n",
        "            "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image captions:\n",
            "Image title: be grateful quote\n",
            "abstract_rect\n",
            "0.2890625\n",
            "\n",
            "Image title: journey quote\n",
            "others_\n",
            "0.0234375\n",
            "\n",
            "Image title: people\n",
            "text_\n",
            "0.296875\n",
            "\n",
            "Image title: dog & cycle\n",
            "text_sign\n",
            "0.3125\n",
            "\n",
            "Image title: journey quote\n",
            "outdoor_\n",
            "0.00390625\n",
            "\n",
            "Image title: people\n",
            "outdoor_mountain\n",
            "0.62890625\n",
            "\n",
            "Image title: people\n",
            "trans_bicycle\n",
            "0.9921875\n",
            "\n",
            "Image title: dog & cycle\n",
            "trans_bicycle\n",
            "0.99609375\n",
            "\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "vZy2DoAGN4i4",
        "outputId": "1fc75356-aaeb-4513-e12c-6b276c9c26eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "print('object detection')\n",
        "results = []\n",
        "for image in images:\n",
        "    result = client.detect_objects(baseURL + image)\n",
        "    results.append(result)\n",
        "for i,result in enumerate(results):\n",
        "    try:\n",
        "        if(len(result.objects)==0):\n",
        "            print('No descriptions present')\n",
        "        else:\n",
        "            for object in result.objects:\n",
        "                print('Image title: ' + names[i])\n",
        "                # \n",
        "                x= object.rectangle.x\n",
        "                y= object.rectangle.y\n",
        "                w=object.rectangle.w\n",
        "                h=object.rectangle.h\n",
        "                print('Object at location')\n",
        "                # 2 coordinates just for sample, we will use all 4 in usecase\n",
        "                print(str(x),',', str(y))\n",
        "                print(str(x),',', str(x+w))\n",
        "                print(str(y), ',',str(y+h))\n",
        "                print(str(x+w),',', str(y+h))\n",
        "                print()\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "object detection\n",
            "Image title: be grateful quote\n",
            "Object at location\n",
            "823 , 220\n",
            "823 , 999\n",
            "220 , 656\n",
            "999 , 656\n",
            "\n",
            "No descriptions present\n",
            "Image title: people\n",
            "Object at location\n",
            "5 , 23\n",
            "5 , 52\n",
            "23 , 157\n",
            "52 , 157\n",
            "\n",
            "Image title: people\n",
            "Object at location\n",
            "65 , 39\n",
            "65 , 104\n",
            "39 , 143\n",
            "104 , 143\n",
            "\n",
            "Image title: people\n",
            "Object at location\n",
            "178 , 20\n",
            "178 , 231\n",
            "20 , 156\n",
            "231 , 156\n",
            "\n",
            "Image title: people\n",
            "Object at location\n",
            "103 , 44\n",
            "103 , 143\n",
            "44 , 186\n",
            "143 , 186\n",
            "\n",
            "Image title: people\n",
            "Object at location\n",
            "119 , 31\n",
            "119 , 185\n",
            "31 , 184\n",
            "185 , 184\n",
            "\n",
            "Image title: people\n",
            "Object at location\n",
            "2 , 76\n",
            "2 , 86\n",
            "76 , 193\n",
            "86 , 193\n",
            "\n",
            "Image title: people\n",
            "Object at location\n",
            "101 , 74\n",
            "101 , 242\n",
            "74 , 193\n",
            "242 , 193\n",
            "\n",
            "Image title: dog & cycle\n",
            "Object at location\n",
            "152 , 23\n",
            "152 , 230\n",
            "23 , 56\n",
            "230 , 56\n",
            "\n",
            "Image title: dog & cycle\n",
            "Object at location\n",
            "44 , 69\n",
            "44 , 109\n",
            "69 , 180\n",
            "109 , 180\n",
            "\n",
            "Image title: dog & cycle\n",
            "Object at location\n",
            "52 , 52\n",
            "52 , 193\n",
            "52 , 150\n",
            "193 , 150\n",
            "\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "4zpzuuT1N4i7",
        "outputId": "acd92f34-17ea-472a-cf54-232eea791883",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# Known entities-> BRANDS\n",
        "\n",
        "analysis = []\n",
        "for image in images:\n",
        "    analyze = client.analyze_image(baseURL +image, ['brands'])\n",
        "    analysis.append(analyze)\n",
        "\n",
        "print('image brands:')\n",
        "\n",
        "for i,result in enumerate(analysis):\n",
        "    print('Image title: ' + names[i])\n",
        "    try:\n",
        "        print('No of brands detected:' + str(len(result.brands)))\n",
        "        for brand in result.brands:\n",
        "            print('Brand Name:' + brand.name)\n",
        "            print('Brand confidence:' + str(brand.confidence))\n",
        "            if(len(result.brands)==0):\n",
        "                print('No descriptions present')\n",
        "            else:\n",
        "               \n",
        "                x= brand.rectangle.x\n",
        "                y= brand.rectangle.y\n",
        "                w=brand.rectangle.w\n",
        "                h=brand.rectangle.h\n",
        "                print('Logo position: ' + names[i])\n",
        "                print(str(x),',', str(y))\n",
        "                print(str(x),',', str(x+w))\n",
        "                print(str(y), ',',str(y+h))\n",
        "                print(str(x+w),',', str(y+h))\n",
        "                print()\n",
        "    except Exception as exp:\n",
        "        print('Image title: ' + names[i])\n",
        "        print(str(exp)) # in production, LOG error instead\n",
        "        pass\n",
        "        \n",
        "            "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image brands:\n",
            "Image title: be grateful quote\n",
            "No of brands detected:0\n",
            "Image title: journey quote\n",
            "No of brands detected:0\n",
            "Image title: people\n",
            "No of brands detected:0\n",
            "Image title: dog & cycle\n",
            "No of brands detected:0\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "WH6b30bmN4i-",
        "outputId": "4e098f83-74ac-4355-88a6-455f1f2e8dc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "#FACIAL EXTRACTION\n",
        "# Known entities-> FACES\n",
        "\n",
        "analysis = []\n",
        "for image in images:\n",
        "    analyze = client.analyze_image(baseURL +image, ['faces'])\n",
        "    analysis.append(analyze)\n",
        "\n",
        "print('image faces:')\n",
        "\n",
        "for i,result in enumerate(analysis):\n",
        "    print('Image title: ' + names[i])\n",
        "    try:\n",
        "        print('No of faces detected:' + str(len(result.faces)))\n",
        "        for face in result.faces:\n",
        "            \n",
        "            if(len(result.faces)==0):\n",
        "                print('No descriptions present')\n",
        "            else:\n",
        "                print('Face Detected:' + face.gender)\n",
        "                print('Guesstimate age:' + str(face.age))\n",
        "                x= face.face_rectangle.left\n",
        "                y= face.face_rectangle.top\n",
        "                w=face.face_rectangle.width\n",
        "                h=face.face_rectangle.height\n",
        "                print('Logo position: ' + names[i])\n",
        "                print(str(x),',', str(y))\n",
        "                print(str(x),',', str(x+w))\n",
        "                print(str(y), ',',str(y+h))\n",
        "                print(str(x+w),',', str(y+h))\n",
        "                print()\n",
        "    except Exception as exp:\n",
        "        print('Image title: ' + names[i])\n",
        "        print(str(exp)) # in production, LOG error instead\n",
        "        pass\n",
        "        \n",
        "            "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image faces:\n",
            "Image title: be grateful quote\n",
            "No of faces detected:0\n",
            "Image title: journey quote\n",
            "No of faces detected:0\n",
            "Image title: people\n",
            "No of faces detected:0\n",
            "Image title: dog & cycle\n",
            "No of faces detected:0\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "id": "NPisAnDSN4jA",
        "outputId": "064ed99b-a26b-4d05-f91b-b201976df68c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# CENSORING for terrorism, nudity, hate content, profantiy, violence etc\n",
        "\n",
        "analysis = []\n",
        "for image in images:\n",
        "    analyze = client.analyze_image(baseURL +image, ['adult'])\n",
        "    analysis.append(analyze)\n",
        "\n",
        "print('Hate/Profanity/Other adult content:')\n",
        "\n",
        "for i,result in enumerate(analysis):\n",
        "    print('Image title: ' + names[i])\n",
        "    try:\n",
        "        #print('No of faces detected:' + str(len(result.faces)))\n",
        "        print('is adult content')\n",
        "        print(result.adult.is_adult_content)\n",
        "        print('is adult content confidence')\n",
        "        print(result.adult.adult_score)\n",
        "        print('is racy content')\n",
        "        print(result.adult.is_racy_content)\n",
        "        print('is racy content confidence')\n",
        "        print(result.adult.racy_score)\n",
        "        print()\n",
        "    except Exception as exp:\n",
        "        print('Image title: ' + names[i])\n",
        "        print(str(exp)) # in production, LOG error instead\n",
        "        print()\n",
        "        pass\n",
        "        \n",
        "            "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hate/Profanity/Other adult content:\n",
            "Image title: be grateful quote\n",
            "is adult content\n",
            "False\n",
            "is adult content confidence\n",
            "0.0012031783116981387\n",
            "is racy content\n",
            "False\n",
            "is racy content confidence\n",
            "0.0021739560179412365\n",
            "\n",
            "Image title: journey quote\n",
            "is adult content\n",
            "False\n",
            "is adult content confidence\n",
            "0.0038798360619693995\n",
            "is racy content\n",
            "False\n",
            "is racy content confidence\n",
            "0.0075361281633377075\n",
            "\n",
            "Image title: people\n",
            "is adult content\n",
            "False\n",
            "is adult content confidence\n",
            "0.009658544324338436\n",
            "is racy content\n",
            "False\n",
            "is racy content confidence\n",
            "0.02743632346391678\n",
            "\n",
            "Image title: dog & cycle\n",
            "is adult content\n",
            "False\n",
            "is adult content confidence\n",
            "0.0025271226186305285\n",
            "is racy content\n",
            "False\n",
            "is racy content confidence\n",
            "0.008063612505793571\n",
            "\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "fD7vM6CAN4jC"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "colab": {
      "name": "computervision.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}